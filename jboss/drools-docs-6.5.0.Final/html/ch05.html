<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Chapter 5. Hybrid Reasoning</title><link rel="stylesheet" type="text/css" href="css/jbossorg.css"/><meta name="generator" content="DocBook XSL-NS Stylesheets V1.76.1"/><link rel="home" href="index.html" title="Drools Documentation"/><link rel="up" href="pt03.html" title="Part III. Drools Runtime and Language"/><link rel="prev" href="pt03.html" title="Part III. Drools Runtime and Language"/><link rel="next" href="ch06.html" title="Chapter 6. User Guide"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/></head><body><p id="title"><a href="http://www.jboss.org" class="site_href"><strong>JBoss.org</strong></a><a href="http://docs.jboss.org/" class="doc_href"><strong>Community Documentation</strong></a></p><ul class="docnav"><li class="previous"><a accesskey="p" href="pt03.html"><strong>Prev</strong></a></li><li class="next"><a accesskey="n" href="ch06.html"><strong>Next</strong></a></li></ul><div class="chapter" title="Chapter 5. Hybrid Reasoning"><div class="titlepage"><div><div><h2 class="title"><a id="HybridReasoningChapter"/>Chapter 5. Hybrid Reasoning</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="ch05.html#d0e4244">5.1. Artificial Intelligence</a></span></dt><dd><dl><dt><span class="section"><a href="ch05.html#d0e4247">5.1.1. A Little History</a></span></dt><dt><span class="section"><a href="ch05.html#d0e4333">5.1.2. Knowledge Representation and Reasoning</a></span></dt><dt><span class="section"><a href="ch05.html#d0e4344">5.1.3. Rule Engines and Production Rule Systems (PRS)</a></span></dt><dt><span class="section"><a href="ch05.html#d0e4429">5.1.4. Hybrid Reasoning Systems (HRS)</a></span></dt><dt><span class="section"><a href="ch05.html#d0e4462">5.1.5. Expert Systems</a></span></dt><dt><span class="section"><a href="ch05.html#d0e4486">5.1.6. Recommended Reading</a></span></dt></dl></dd><dt><span class="section"><a href="ch05.html#ReteOO">5.2. Rete Algorithm</a></span></dt><dt><span class="section"><a href="ch05.html#ReteOOSection">5.3. ReteOO Algorithm</a></span></dt><dt><span class="section"><a href="ch05.html#PHREAK">5.4. PHREAK Algorithm</a></span></dt></dl></div><div class="section" title="5.1. Artificial Intelligence"><div class="titlepage"><div><div><h2 class="title"><a id="d0e4244"/>5.1. Artificial Intelligence</h2></div></div></div><div class="section" title="5.1.1. A Little History"><div class="titlepage"><div><div><h3 class="title"><a id="d0e4247"/>5.1.1. A Little History</h3></div></div></div><p>Over the last few decades <em class="firstterm">artificial
    intelligence</em> (AI) became an unpopular term, with the well-known
    <a class="link" href="http://en.wikipedia.org/wiki/AI_winter">"AI
    Winter"</a>. There were large boasts from scientists and engineers
    looking for funding, which never lived up to expectations, resulting in many
    failed projects. <a class="link" href="http://en.wikipedia.org/wiki/Thinking_Machines_Corporation">Thinking
    Machines Corporation</a> and the <a class="link" href="http://en.wikipedia.org/wiki/Fifth-generation_computer">5th
    Generation Computer</a> (5GP) project probably exemplify best the
    problems at the time.</p><p>Thinking Machines Corporation was one of the leading AI firms in
    1990, it had sales of nearly $65 million. Here is a quote from its
    brochure:</p><p><span class="quote">“<span class="quote">Some day we will build a thinking machine. It will be a truly
    intelligent machine. One that can see and hear and speak. A machine that
    will be proud of us.</span>”</span></p><p>Yet 5 years later it filed for bankruptcy protection under Chapter 11. 
    The site inc.com has a fascinating article titled <a class="link" href="http://www.inc.com/magazine/19950915/2622.html">"The Rise and
    Fall of Thinking Machines"</a>. The article covers the growth of the
    industry and how a cosy relationship with Thinking Machines and <a class="link" href="http://en.wikipedia.org/wiki/DARPA">DARPA</a> over-heated
    the market, to the point of collapse. It explains how and why commerce
    moved away from AI and towards more practical number-crunching super
    computers.</p><p>The 5th Generation Computer project was a USD 400 million project in Japan to build a next generation
      computer. Valves (or Tubes) was the first generation, transistors the second, integrated circuits the third and
      finally microprocessors was the fourth. The fifth was intended to be a machine capable of effective Artificial
      Intelligence. This project spurred an "arms" race with the UK and USA, that caused much of the AI bubble. The 5GP
      would provide massive multi-cpu parallel processing hardware along with powerful knowledge representation and
      reasoning software via <em class="firstterm">Prolog</em>; a type of <em class="firstterm"> expert system</em>. By 1992 the
      project was considered a failure and cancelled. It was the largest and most visible commercial venture for Prolog,
      and many of the failures are pinned on the problems of trying to run a logic based programming language
      concurrently on multi CPU hardware with effective results. Some believe that the failure of the 5GP project
      tainted Prolog and relegated it to academia, see <a class="link" href="http://www.dvorak.org/blog/whatever-happened-to-prolog/">"Whatever Happened to Prolog"</a> by
      John C. Dvorak.</p><p>However while research funding dried up and the term AI became less
    used, many green shoots where planted and continued more quietly under
    discipline specific names: <em class="firstterm">cognitive systems</em>,
    <em class="firstterm">machine learning</em>, <em class="firstterm">intelligent
    systems</em>,<em class="firstterm"> knowledge representation and
    reasoning</em>. Offshoots of these then made their way into
    commercial systems, such as expert systems in the <em class="firstterm">Business
    Rules Management System</em> (BRMS) market.</p><p><em class="firstterm">Imperative</em>, system based languages, languages such as C, C++, Java and C#/.Net have
      dominated the last 20 years, enabled by the practicality of the languages and ability to run with good performance
      on commodity hardware. However many believe there is a renaissance underway in the field of AI, spurred by
      advances in hardware capabilities and AI research. In 2005 Heather Havenstein authored <a class="link" href="http://www.computerworld.com/s/article/99691/Spring_comes_to_AI_winter">"Spring comes to AI
        winter"</a> which outlines a case for this resurgence. Norvig and Russel dedicate several pages to what
      factors allowed the industry to overcome it's problems and the research that came about as a result:</p><div class="blockquote"><table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote"><tr><td width="10%" valign="top"> </td><td width="80%" valign="top"><p>
          Recent years have seen a revolution in both the content and
          the methodology of work in artificial intelligence. It is now more common
          to build on existing theories than to propose brand-new ones, to base
          claims on rigorous theorems or hard experimental evidence rather than on
          intuition, and to show relevance to real-world applications rather than
          toy examples.          
        </p></td><td width="10%" valign="top"> </td></tr><tr><td width="10%" valign="top"> </td><td colspan="2" align="right" valign="top">--<span class="attribution">Artificial Intelligence: A Modern Approach</span></td></tr></table></div><p><em class="firstterm">Computer vision</em>, <em class="firstterm">neural networks</em>, <em class="firstterm">machine
        learning</em> and <em class="firstterm">knowledge representation and reasoning</em> (KRR) have made great
      strides towards becoming practical in commercial environments. For example, vision-based systems can now fully map
      out and navigate their environments with strong recognition skills. As a result we now have self-driving cars
      about to enter the commercial market. <em class="firstterm">Ontological</em> research, based around description logic,
      has provided very rich semantics to represent our world. Algorithms such as the tableaux algorithm have made it
      possible to use those rich semantics effectively in large complex ontologies. Early KRR systems, like Prolog in
      5GP, were dogged by the limited semantic capabilities and memory restrictions on the size of those
      ontologies.</p></div><div class="section" title="5.1.2. Knowledge Representation and Reasoning"><div class="titlepage"><div><div><h3 class="title"><a id="d0e4333"/>5.1.2. Knowledge Representation and Reasoning</h3></div></div></div><p>In A Little History talks about AI as a broader subject and touches
    on Knowledge Representation and Reasoning (KRR) and also Expert Systems,
    I'll come back to Expert Systems later.</p><p>KRR is about how we represent our knowledge in symbolic form, i.e. how we describe something. Reasoning is
      about how we go about the act of thinking using this knowledge. System based object-oriented languages, like C++,
      Java and C#, have data definitions called classes for describing the composition and behaviour of modeled
      entities. In Java we call exemplars of these described things beans or instances. However those classification
      systems are limited to ensure computational efficiency. Over the years researchers have developed increasingly
      sophisticated ways to represent our world. Many of you may already have heard of OWL (Web Ontology Language).
      There is always a gap between what can be theoretically represented and what can be used computationally in
      practically timely manner, which is why OWL has different sub-languages from Lite to Full. It is not believed that
      any reasoning system can support OWL Full. However, algorithmic advances continue  to narrow that gap and improve
      the expressiveness available to reasoning engines.</p><p>There are also many approaches to how these systems go about
    thinking. You may have heard discussions comparing the merits of
    forward chaining, which is reactive and data driven, with backward chaining,
    which is passive and query driven. Many other types of reasoning
    techniques exist, each of which enlarges the scope of the problems we can
    tackle declaratively. To list just a few: imperfect reasoning (fuzzy
    logic, certainty factors), defeasible logic, belief systems, temporal
    reasoning and correlation. You don't need to understand all these terms
    to understand and use Drools. They are just there to give
    an idea of the range of scope of research topics, which is actually far
    more extensive, and continues to grow as researchers
    push new boundaries.</p><p>KRR is often referred to as the core of Artificial Intelligence. Even
    when using biological approaches like neural networks, which model the
    brain and are more about pattern recognition than thinking, they still
    build on KRR theory. My first endeavours with Drools were engineering
    oriented, as I had no formal training or understanding of KRR. Learning
    KRR has allowed me to get a much wider theoretical background. Allowing me
    to better understand both what I've done and where I'm going, as it
    underpins nearly all of the theoretical side to our Drools R&amp;D. It
    really is a vast and fascinating subject that will pay dividends for those
    who take the time to learn. I know it did and still does for me. Bracham and
    Levesque have written a seminal piece of work, called "Knowledge
    Representation and Reasoning" that is a must read for anyone wanting to build strong
    foundations. I would also recommend the Russel and Norvig
    book "Artificial Intelligence, a modern approach" which also covers
    KRR.</p></div><div class="section" title="5.1.3. Rule Engines and Production Rule Systems (PRS)"><div class="titlepage"><div><div><h3 class="title"><a id="d0e4344"/>5.1.3. Rule Engines and Production Rule Systems (PRS)</h3></div></div></div><p>We've now covered a brief history of AI and learnt that the core of AI is formed around KRR. We've shown than
      KRR is a vast and fascinating subject which forms the bulk of the theory driving Drools R&amp;D.</p><p>The rule engine is the computer program that delivers KRR
    functionality to the developer. At a high level it has three
    components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Ontology</p></li><li class="listitem"><p>Rules</p></li><li class="listitem"><p>Data</p></li></ul></div><p>As previously mentioned the ontology is the representation model we
    use for our "things". It could use records or Java classes or full-blown
    OWL based ontologies. The rules perform the reasoning, i.e., they facilitate
    "thinking". The distinction between rules and ontologies blurs a little with
    OWL based ontologies, whose richness is rule based.</p><p>The term "rules engine" is quite ambiguous in that it can be any system that uses rules, in any form, that can
      be applied to data to produce outcomes. This includes simple systems like form validation and dynamic expression
      engines. The book "How to Build a Business Rules Engine" (2004) by Malcolm Chisholm exemplifies this ambiguity.
      The book is actually about how to build and alter a database schema to hold validation rules. The book then shows
      how to generate Visual Basic code from those validation rules to validate data entry. While perfectly valid, this
      is very different to what we are talking about.</p><p>Drools started life as a specific type of rule engine called a
    Production Rule System (PRS) and was based around the Rete algorithm
    (usually pronounced as two syllables, e.g., REH-te or RAY-tay). The
    Rete algorithm, developed by Charles Forgy in 1974, forms the brain of a
    Production Rule System and is able to scale to a large number of rules
    and facts. A Production Rule is a two-part structure: the engine matches
    facts and data against Production Rules - also called Productions or just
    Rules - to infer conclusions which result in actions.</p><pre><code class="language-java">when
    &lt;conditions&gt;
then
    &lt;actions&gt;;</code></pre><p>The process of matching the new or existing facts against Production Rules is called <em class="firstterm">pattern
        matching</em><a id="d0e4373" class="indexterm"/>, which is performed by the <em class="firstterm">inference engine</em><a id="d0e4379" class="indexterm"/>. Actions execute in response to changes in data, like a database trigger; we say this is a
        <em class="firstterm">data driven</em><a id="d0e4385" class="indexterm"/> approach to reasoning. The actions themselves can change data, which in turn could match against
      other rules causing them to fire; this is referred to as <a id="d0e4389" class="indexterm"/>forward chaining</p><p>Drools 5.x implements and extends the <em class="firstterm">Rete</em><a id="d0e4397" class="indexterm"/> algorithm. This extended Rete algorithm is named <em class="firstterm">ReteOO</em><a id="d0e4403" class="indexterm"/>, signifying that Drools has an enhanced and optimized implementation of the
      Rete algorithm for object oriented systems. Other Rete based engines
      also have marketing terms for their proprietary enhancements to Rete, like RetePlus and Rete III. The most common
      enhancements are covered in "Production Matching for Large Learning Systems" (1995) by Robert B. Doorenbos'
      thesis, which presents Rete/UL. Drools 6.x introduces a new lazy algorithm named <em class="firstterm">PHREAK</em><a id="d0e4409" class="indexterm"/>; which is covered in more detail in the PHEAK algorithm section.</p><p>The Rules are stored in the <a id="d0e4415" class="indexterm"/> Production Memory and the facts that the Inference Engine
    matches against are kept in the <a id="d0e4419" class="indexterm"/> Working Memory. Facts are asserted into the Working Memory
    where they may then be modified or retracted. A system with a large number
    of rules and facts may result in many rules being true for the same fact
    assertion; these rules are said to be in conflict. The Agenda manages the
    execution order of these conflicting rules using a Conflict Resolution
    strategy.</p><div class="figure"><a id="d0e4423"/><p class="title"><strong>Figure 5.1. High-level View of a Production Rule System</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/rule-engine-inkscape.png" align="middle" alt="High-level View of a Production Rule System"/></div></div></div><br class="figure-break"/></div><div class="section" title="5.1.4. Hybrid Reasoning Systems (HRS)"><div class="titlepage"><div><div><h3 class="title"><a id="d0e4429"/>5.1.4. Hybrid Reasoning Systems (HRS)</h3></div></div></div><p>You may have read discussions comparing the merits of forward
    chaining (reactive and data driven) or backward chaining (passive query).
    Here is a quick explanation of these two main types of reasoning.</p><p>Forward chaining is "data-driven" and thus reactionary, with facts
    being asserted into working memory, which results in one or more rules
    being concurrently true and scheduled for execution by the Agenda. In
    short, we start with a fact, it propagates through the rules, and we end in a
    conclusion.</p><div class="figure"><a id="d0e4436"/><p class="title"><strong>Figure 5.2. Forward Chaining</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Forward_Chaining.png" align="middle" alt="Forward Chaining"/></div></div></div><br class="figure-break"/><p>Backward chaining is "goal-driven", meaning that we start with a
    conclusion which the engine tries to satisfy. If it can't, then it searches
    for conclusions that it can satisfy. These are known as subgoals, that
    will help satisfy some unknown part of the current goal. It continues this
    process until either the initial conclusion is proven or there are no more
    subgoals. Prolog is an example of a Backward Chaining engine. Drools can
    also do backward chaining, which we refer to as derivation queries.</p><div class="figure"><a id="d0e4444"/><p class="title"><strong>Figure 5.3. Backward Chaining</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Backward_Chaining.png" align="middle" alt="Backward Chaining"/></div></div></div><br class="figure-break"/><p>Historically you would have to make a choice between systems like
    OPS5 (forward) or Prolog (backward). Nowadays many modern systems provide both
    types of reasoning capabilities. There are also many other types of
    reasoning techniques, each of which enlarges the scope of the problems we
    can tackle declaratively. To list just a few: imperfect reasoning (fuzzy
    logic, certainty factors), defeasible logic, belief systems, temporal
    reasoning and correlation. Modern systems are merging these capabilities,
    and others not listed, to create <em class="firstterm">hybrid reasoning
    systems</em> (HRS).</p><p>While Drools started out as a PRS, 5.x introduced Prolog style
    backward chaining reasoning as well as some functional programming styles.
    For this reason we now prefer the term Hybrid Reasoning System when describing Drools.
    </p><p>Drools currently provides crisp reasoning, but imperfect reasoning is
    almost ready. Initially this will be imperfect reasoning with fuzzy logic;
    later we'll add support for other types of uncertainty. Work is also under
    way to bring OWL based ontological reasoning, which will integrate with
    our <em class="firstterm">traits</em> system. We also continue to improve our
    functional programming capabilities.</p></div><div class="section" title="5.1.5. Expert Systems"><div class="titlepage"><div><div><h3 class="title"><a id="d0e4462"/>5.1.5. Expert Systems</h3></div></div></div><p>You will often hear the terms <em class="firstterm">expert systems</em>
    used to refer to <em class="firstterm">production rule systems</em> or
    <em class="firstterm">Prolog</em>-like systems. While this is normally
    acceptable, it's technically incorrect as these are frameworks to build expert
    systems with, rather than expert systems themselves. It becomes an
    expert system once there is an ontological model to represent the domain
    and there are facilities for knowledge acquisition and explanation.
    </p><p><em class="firstterm">Mycin</em> is the most famous expert system, built
    during the 70s. It is still heavily covered in academic literature, such
    as the recommended book "Expert Systems" by Peter Jackson.</p><div class="figure"><a id="d0e4480"/><p class="title"><strong>Figure 5.4. Early History of Expert Systems</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/expertsytem_history.png" align="middle" alt="Early History of Expert Systems"/></div></div></div><br class="figure-break"/></div><div class="section" title="5.1.6. Recommended Reading"><div class="titlepage"><div><div><h3 class="title"><a id="d0e4486"/>5.1.6. Recommended Reading</h3></div></div></div><p><span class="bold"><strong>General AI, KRR and Expert System
    Books</strong></span></p><p>For those wanting to get a strong theoretical background in KRR and
    expert systems, I'd strongly recommend the following books. "Artificial
    Intelligence: A Modern Approach" is a must have, for anyone's
    bookshelf.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Introduction to Expert Systems</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Peter Jackson</p></li></ul></div></li></ul></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Expert Systems: Principles and Programming</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Joseph C. Giarratano, Gary D. Riley</p></li></ul></div></li></ul></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Knowledge Representation and Reasoning</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Ronald J. Brachman, Hector J. Levesque</p></li></ul></div></li></ul></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Artificial Intelligence : A Modern Approach.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Stuart Russell and Peter Norvig</p></li></ul></div></li></ul></div><div class="figure"><a id="d0e4526"/><p class="title"><strong>Figure 5.5. Recommended Reading</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/book_recommendations.png" align="middle" alt="Recommended Reading"/></div></div></div><br class="figure-break"/><p><span class="bold"><strong>Papers</strong></span></p><p>Here are some recommended papers that cover interesting areas
    in rule engine research:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Production Matching for Large Learning Systems: Rete/UL
        (1993)</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Robert B. Doorenbos</p></li></ul></div></li><li class="listitem"><p>Advances In Rete Pattern Matching</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Marshall Schor, Timothy P. Daly, Ho Soo Lee, Beth R.
            Tibbitts (AAAI 1986)</p></li></ul></div></li><li class="listitem"><p>Collection-Oriented Match</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Anurag Acharya and Milind Tambe (1993)</p></li></ul></div></li><li class="listitem"><p>The Leaps Algorithm</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Don Batery (1990)</p></li></ul></div></li><li class="listitem"><p>Gator: An Optimized Discrimination Network for Active Database
        Rule Condition Testing</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Eric Hanson , Mohammed S. Hasan (1993)</p></li></ul></div></li></ul></div><p><span class="bold"><strong>Drools Books</strong></span></p><p>There are currently three Drools books, all from Packt
    Publishing.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>JBoss Drools Business Rules</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Paul Browne</p></li></ul></div></li><li class="listitem"><p>Drools JBoss Rules 5.0 Developers Guide</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Michal Bali</p></li></ul></div></li><li class="listitem"><p>Drools Developer's Cookbook</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Lucas Amador</p></li></ul></div></li></ul></div><div class="figure"><a id="d0e4600"/><p class="title"><strong>Figure 5.6. Recommended Reading</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/drools_book_recommendations.png" align="middle" alt="Recommended Reading"/></div></div></div><br class="figure-break"/></div></div><div class="section" title="5.2. Rete Algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="ReteOO"/>5.2. Rete Algorithm</h2></div></div></div><p>The <span class="emphasis"><em>Rete</em></span> algorithm was invented by Dr. Charles
  Forgy and documented in his PhD thesis in 1978-79. A simplified version of
  the paper was published in 1982 (<a class="link" href="http://citeseer.ist.psu.edu/context/505087/0">http://citeseer.ist.psu.edu/context/505087/0</a>).
  The latin word "rete" means "net" or "network". The Rete algorithm can be
  broken into 2 parts: rule compilation and runtime execution.</p><p>The compilation algorithm describes how the Rules in the Production
  Memory are processed to generate an efficient discrimination network. In
  non-technical terms, a discrimination network is used to filter data as it
  propagates through the network. The nodes at the top of the network would
  have many matches, and as we go down the network, there would be fewer
  matches. At the very bottom of the network are the terminal nodes. In Dr.
  Forgy's 1982 paper, he described 4 basic nodes: root, 1-input, 2-input and
  terminal.</p><div class="figure"><a id="d0e4619"/><p class="title"><strong>Figure 5.7. Rete Nodes</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Rete_Nodes.png" align="middle" alt="Rete Nodes"/></div></div></div><br class="figure-break"/><p>The root node is where all objects enter the network. From there, it
  immediately goes to the ObjectTypeNode. The purpose of the ObjectTypeNode is
  to make sure the engine doesn't do more work than it needs to. For example,
  say we have 2 objects: Account and Order. If the rule engine tried to
  evaluate every single node against every object, it would waste a lot of
  cycles. To make things efficient, the engine should only pass the object to
  the nodes that match the object type. The easiest way to do this is to
  create an ObjectTypeNode and have all 1-input and 2-input nodes descend from
  it. This way, if an application asserts a new Account, it won't propagate to
  the nodes for the Order object. In Drools when an object is asserted it
  retrieves a list of valid ObjectTypesNodes via a lookup in a HashMap from
  the object's Class; if this list doesn't exist it scans all the
  ObjectTypeNodes finding valid matches which it caches in the list. This
  enables Drools to match against any Class type that matches with an
  <code class="literal">instanceof</code> check.</p><div class="figure"><a id="d0e4630"/><p class="title"><strong>Figure 5.8. ObjectTypeNodes</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Object_Type_Nodes.png" align="middle" alt="ObjectTypeNodes"/></div></div></div><br class="figure-break"/><p>ObjectTypeNodes can propagate to AlphaNodes, LeftInputAdapterNodes and
  BetaNodes. AlphaNodes are used to evaluate literal conditions. Although the
  1982 paper only covers equality conditions, many RETE implementations
  support other operations. For example, <code class="code">Account.name == "Mr
  Trout"</code> is a literal condition. When a rule has multiple literal
  conditions for a single object type, they are linked together. This means
  that if an application asserts an Account object, it must first satisfy the
  first literal condition before it can proceed to the next AlphaNode. In Dr.
  Forgy's paper, he refers to these as IntraElement conditions. The following
  diagram shows the AlphaNode combinations for Cheese( name == "cheddar",
  strength == "strong" ):</p><div class="figure"><a id="d0e4641"/><p class="title"><strong>Figure 5.9. AlphaNodes</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Alpha_Nodes.png" align="middle" alt="AlphaNodes"/></div></div></div><br class="figure-break"/><p>Drools extends Rete by optimizing the propagation from ObjectTypeNode
  to AlphaNode using hashing. Each time an AlphaNode is added to an
  ObjectTypeNode it adds the literal value as a key to the HashMap with the
  AlphaNode as the value. When a new instance enters the ObjectType node,
  rather than propagating to each AlphaNode, it can instead retrieve the
  correct AlphaNode from the HashMap,thereby avoiding unnecessary literal
  checks.</p><p>There are two two-input nodes, JoinNode and NotNode, and both are
  types of BetaNodes. BetaNodes are used to compare 2 objects, and their
  fields, to each other. The objects may be the same or different types. By
  convention we refer to the two inputs as left and right. The left input for
  a BetaNode is generally a list of objects; in Drools this is a Tuple. The
  right input is a single object. Two Nodes can be used to implement 'exists'
  checks. BetaNodes also have memory. The left input is called the Beta Memory
  and remembers all incoming tuples. The right input is called the Alpha
  Memory and remembers all incoming objects. Drools extends Rete by performing
  indexing on the BetaNodes. For instance, if we know that a BetaNode is
  performing a check on a String field, as each object enters we can do a hash
  lookup on that String value. This means when facts enter from the opposite
  side, instead of iterating over all the facts to find valid joins, we do a
  lookup returning potentially valid candidates. At any point a valid join is
  found the Tuple is joined with the Object; which is referred to as a partial
  match; and then propagated to the next node.</p><div class="figure"><a id="d0e4651"/><p class="title"><strong>Figure 5.10. JoinNode</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Join_Node.png" align="middle" alt="JoinNode"/></div></div></div><br class="figure-break"/><p>To enable the first Object, in the above case Cheese, to enter the
  network we use a LeftInputNodeAdapter - this takes an Object as an input and
  propagates a single Object Tuple.</p><p>Terminal nodes are used to indicate a single rule having matched all
  its conditions; at this point we say the rule has a full match. A rule with
  an 'or' conditional disjunctive connective results in subrule generation for
  each possible logically branch; thus one rule can have multiple terminal
  nodes.</p><p>Drools also performs node sharing. Many rules repeat the same
  patterns, and node sharing allows us to collapse those patterns so that they
  don't have to be re-evaluated for every single instance. The following two
  rules share the first pattern, but not the last:</p><pre><code class="no-highlight">rule
when
    Cheese( $cheddar : name == "cheddar" )
    $person : Person( favouriteCheese == $cheddar )
then
    System.out.println( $person.getName() + " likes cheddar" );
end</code></pre><pre><code class="no-highlight">rule
when
    Cheese( $cheddar : name == "cheddar" )
    $person : Person( favouriteCheese != $cheddar )
then
    System.out.println( $person.getName() + " does not like cheddar" );
end</code></pre><p>As you can see below, the compiled Rete network shows that the alpha
  node is shared, but the beta nodes are not. Each beta node has its own
  TerminalNode. Had the second pattern been the same it would have also been
  shared.</p><div class="figure"><a id="d0e4669"/><p class="title"><strong>Figure 5.11. Node Sharing</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/Node_Sharing.png" align="middle" alt="Node Sharing"/></div></div></div><br class="figure-break"/></div><div class="section" title="5.3. ReteOO Algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="ReteOOSection"/>5.3. ReteOO Algorithm</h2></div></div></div><p>The <span class="emphasis"><em>ReteOO</em></span> was developed throughout the 3, 4 and 5 series releases. It takes the RETE
    algorithm and applies well known enhancements, all of which are covered by existing academic literature:</p><p>Node sharing</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Sharing is applied to both the alpha and beta network. The beta network sharing is always from the root
          pattern.</p></li></ul></div><p>Alpha indexing</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Alpha Nodes with many children use a hash lookup mechanism, to avoid testing each result.</p></li></ul></div><p>Beta indexing</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Join, Not and Exist nodes indexing their memories using a hash. This reduces the join attempts for equal
          checks. Recently range indexing was added to Not and Exists.</p></li></ul></div><p>Tree based graphs</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Join matches did not contain any references to their parent or children matches. Deletions would have to
          recalculate all join matches again, which involves recreating all those join match objects, to be able to find
          the parts of the network where the tuples should be deleted. This is called symmetrical propagation. A tree
          graph provides parent and children references, so a deletion is just a matter of following those references.
          This is asymmetrical propagation. The result is faster and less impact on the GC, and more robust because
          changes in values will not cause memory leaks if they happen without the engine being notified.</p></li></ul></div><p>Modify-in-place</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Traditional RETE implements a modify as a delete + insert. This causes all join tuples to be GC'd, many of
          which are recreated again as part of the insert. Modify-in-place instead propagates as a single pass, every
          node is inspected </p></li></ul></div><p>Property reactive</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Also called "new trigger condition". Allows more fine grained reactivity to updates. A Pattern can react
          to changes to specific properties and ignore others. This alleviates problems of recursion and also helps with
          performance.</p></li></ul></div><p>Sub-networks</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Not, Exists and Accumulate can each have nested conditional elements, which forms sub networks.</p></li></ul></div><p>Backward Chaining</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Prolog style derivation trees for backward chaining are supported. The implementation is stack based, so
          does not have method recursion issues for large graphs.</p></li></ul></div><p>Lazy Truth Maintenance</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Truth maintenance has a runtime cost, which is incurred whether TMS is used or not. Lazy TMS only turns it
          on, on first use. Further it's only turned on for that object type, so other object types do not incur the
          runtime cost.</p></li></ul></div><p>Heap based agenda</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The agenda uses a binary heap queue to sort rule matches by salience, rather than any linear search or
          maintenance approach.</p></li></ul></div><p>Dynamic Rules</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Rules can be added and removed at runtime, while the engine is still populated with data.</p></li></ul></div></div><div class="section" title="5.4. PHREAK Algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="PHREAK"/>5.4. PHREAK Algorithm</h2></div></div></div><p>Drools 6 introduces a new algorithm, that attempts to address some of the core issues of RETE. The algorithm is
    not a rewrite form scratch and incorporates all of the existing code from ReteOO, and all its enhancements. While
    PHREAK is an evolution of the RETE algorithm, it is no longer classified as a RETE implementation. In the same way
    that once an animal evolves beyond a certain point and key characteristics are changed, the animal becomes
    classified as new species. There are two key RETE characteristics that strongly identify any derivative strains,
    regardless of optimizations. That it is an eager, data oriented algorithm. Where all work is doing done the insert,
    update or delete actions; eagerly producing all partial matches for all rules. PHREAK in contrast is characterised
    as a lazy, goal oriented algorithm; where partial matching is aggressively delayed. </p><p>This eagerness of RETE can lead to a lot of churn in large systems, and much wasted work. Where wasted work is
    classified as matching efforts that do not result in a rule firing.</p><p>PHREAK was heavily inspired by a number of algorithms; including (but not limited to) LEAPS, RETE/UL and
    Collection-Oriented Match. PHREAK has all enhancements listed in the ReteOO section. In addition it adds the
    following set of enhancements, which are explained in more detail in the following paragraphs.</p><p>
    </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Three layers of contextual memory; Node, Segment and Rule memories.</p></li><li class="listitem"><p>Rule, segment and node based linking.</p></li><li class="listitem"><p>Lazy (delayed) rule evaluation.</p></li><li class="listitem"><p>Isolated rule evaluation.</p></li><li class="listitem"><p>Set oriented propagations.</p></li><li class="listitem"><p>Stack based evaluations, with pause and resume.</p></li></ul></div><p>
  </p><p>When the PHREAK engine is started all rules are said to be unlinked, no rule evaluation can happen while rules
    are unlinked. The insert, update and deletes actions are queued before entering the beta network. A simple
    heuristic, based on the rule most likely to result in firings, is used to select the next rule for evaluation; this
    delays the evaluation and firing of the other rules. Only once a rule has all right inputs populated will the rule
    be considered linked in, although no work is yet done. Instead a goal is created, that represents the rule, and
    placed into a priority queue; which is ordered by salience. Each queue itself is associated with an AgendaGroup.
    Only the active AgendaGroup will inspect its queue, popping the goal for the rule with the highest salience and
    submitting it for evaluation. So the work done shifts from the insert, update, delete phase to the fireAllRules
    phase. Only the rule for which the goal was created is evaluated, other potential rule evaluations from those facts
    are delayed. While individual rules are evaluated, node sharing is still achieved through the process of
    segmentation, which is explained later.</p><p>Each successful join attempt in RETE produces a tuple (or token, or partial match) that will be propagated to
    the child nodes. For this reason it is characterised as a tuple oriented algorithm. For each child node that it
    reaches it will attempt to join with the other side of the node, again each successful join attempt will be
    propagated straight away. This creates a descent recursion effect. Thrashing the network of nodes as it ripples up
    and down, left and right from the point of entry into the beta network to all the reachable leaf nodes.</p><p>PHREAK propagation is set oriented (or collection-oriented), instead of tuple oriented. For the rule being
    evaluated it will visit the first node and process all queued insert, update and deletes. The results are added to a
    set and the set is propagated to the child node. In the child node all queued inset, update and deletes are
    processed, adding the results to the same set. Once finished that set is propagated to the next child node, and so
    on until the terminal node is reached. This creates a single pass, pipeline type effect, that is isolated to the
    current rule being evaluated. This creates a batch process effect which can provide performance advantages for
    certain rule constructs; such as sub-networks with accumulates. In the future it will leans itself to being able to
    exploit multi-core machines in a number of ways.</p><p>The Linking and Unlinking uses a layered bit mask system, based on a network segmentation. When the rule network
    is built segments are created for nodes that are shared by the same set of rules. A rule itself is made up from a
    path of segments, although if there is no sharing that will be a single segment. A bit-mask offset is assigned to
    each node in the segment. Also another bit mask (the layering) is assigned to each segment in the rule's path. When
    there is at least one input (data propagation) the node's bit is set to on. When each node has its bit set to on
    the segment's bit is also set to on. Conversely if any node's bit is set to off, the segment is then also set to
    off. If each segment in the rule's path is set to on, the rule is said to be linked in and a goal is created to
    schedule the rule for evaluation. The same bit-mask technique is used to also track dirty node, segments and rules;
    this allows for a rule already link in to be scheduled for evaluation if it's considered dirty since it was last
    evaluated.</p><p>This ensures that no rule will ever evaluate partial matches, if it's impossible for it to result in rule
    instances because one of the joins has no data. This is possible in RETE and it will merrily churn away producing
    martial match attempts for all nodes, even if the last join is empty.</p><p>While the incremental rule evaluation always starts from the root node, the dirty bit masks are used to allow
    nodes and segments that are not dirty to be skipped.</p><p>Using the existence of at at least one items of data per node, is a fairly basic heuristic. Future work would
    attempt to delay the linking even further; using techniques such as arc consistency to determine whether or not
    matching will result in rule instance firings.</p><p>Where as RETE has just a singe unit of memory, the node memory, PHREAK has 3 levels of memory. This allows for
    much more contextual understanding during evaluation of a Rule.</p><div class="figure"><a id="d0e4796"/><p class="title"><strong>Figure 5.12. PHREAK 3 Layered memory system</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/LayeredMemory.png" align="middle" alt="PHREAK 3 Layered memory system"/></div></div></div><br class="figure-break"/><p>Example 1 shows a single rule, with three patterns; A, B and C. It forms a single segment, with bits 1, 2 and 4
    for the nodes. The single segment has a bit offset of 1.</p><div class="figure"><a id="d0e4804"/><p class="title"><strong>Figure 5.13. Example1: Single rule, no sharing</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/segment1.png" align="middle" alt="Example1: Single rule, no sharing"/></div></div></div><br class="figure-break"/><p>Example 2 demonstrates what happens when another rule is added that shares the pattern A. A is placed in its
    own segment, resulting in two segments per rule. Those two segments form a path, for their respective rules. The
    first segment is shared by both paths. When A is linked the segment becomes linked, it then iterates each path the
    segment is shared by, setting the bit 1 to on. If B and C are later turned on, the second segment for path R1 is
    linked in; this causes bit 2 to be turned on for R1. With bit 1 and bit 2 set to on for R1, the rule is now linked
    and a goal created to schedule the rule for later evaluation and firing.</p><p>When a rule is evaluated it is the segments that allow the results of matching to be shared. Each segment has a
    staging memory to queue all insert, update and deletes for that segment. If R1 was to evaluated it would process A
    and result in a set of tuples. The algorithm detects that there is a segmentation split and will create peered
    tuples for each insert, update and delete in the set and add them to R2's staging memory. Those tuples will be
    merged with any existing staged tuples and wait for R2 to eventually be evaluated.</p><div class="figure"><a id="d0e4814"/><p class="title"><strong>Figure 5.14. Example 2: Two rules, with sharing</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/segment2.png" align="middle" alt="Example 2: Two rules, with sharing"/></div></div></div><br class="figure-break"/><p>Example 3 adds a third rule and demonstrates what happens when A and B are shared. Only the bits for the
    segments are shown this time. Demonstrating that R4 has 3 segments, R3 has 3 segments and R1 has 2 segments. A and B
    are shared by R1, R3 and R4. While D is shared by R3 and R4.</p><div class="figure"><a id="d0e4822"/><p class="title"><strong>Figure 5.15. Example 3: Three rules, with sharing</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/segment3.png" align="middle" alt="Example 3: Three rules, with sharing"/></div></div></div><br class="figure-break"/><p>Sub-networks are formed when a Not, Exists or Accumulate node contain more than one element. In Example 4 "B
    not( C )" forms the sub network, note that "not(C)" is a single element and does not require a sub network and is
    merged inside of the Not node.</p><p>The sub network gets its own segment. R1 still has a path of two segments. The sub network forms another "inner"
    path. When the sub network is linked in, it will link in the outer segment.</p><div class="figure"><a id="d0e4832"/><p class="title"><strong>Figure 5.16. Example 4 : Single rule, with sub-network and no sharing</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/segment4.png" align="middle" alt="Example 4 : Single rule, with sub-network and no sharing"/></div></div></div><br class="figure-break"/><p>Example 5 shows that the sub-network nodes can be shard by a rule that does not have a sub-network. This results
    in the sub-network segment being split into two.</p><div class="figure"><a id="d0e4840"/><p class="title"><strong>Figure 5.17. Example 5: Two rules, one with a sub-network and sharing</strong></p><div class="figure-contents"><div class="mediaobject" align="center"><img src="images/HybridReasoning/segment5.png" align="middle" alt="Example 5: Two rules, one with a sub-network and sharing"/></div></div></div><br class="figure-break"/><p>Not nodes with constraints and accumulate nodes have special behaviour and can never unlink a segment, and are
    always considered to have their bits on.</p><p>All rule evaluations are incremental, and will not waste work recomputing matches that it has already
    produced.</p><p>The evaluation algorithm is stack based, instead of method recursion. Evaluation can be paused and resumed at
    any time, via the use of a StackEntry to represent current node being evaluated. </p><p>When a rule evaluation reaches a sub-network a StackEntry is created for the outer path segment and the
    sub-network segment. The sub-network segment is evaluated first, when the set reaches the end of the sub-network
    path it is merged into a staging list for the outer node it feeds into. The previous StackEntry is then resumed
    where it can process the results of the sub network. This has the added benefit that all work is processed in a
    batch, before propagating to the child node; which is much more efficient for accumulate nodes.</p><p>The same stack system can be used for efficient backward chaining. When a rule evaluation reaches a query node
    it again pauses the current evaluation, by placing it on the stack. The query is then evaluated which produces a
    result set, which is saved in a memory location for the resumed StackEntry to pick up and propagate to the child
    node. If the query itself called other queries the process would repeat, with the current query being paused and a
    new evaluation setup for the current query node.</p><p>One final point on performance. One single rule in general will not evaluate any faster with PHREAK than it does
    with RETE. For a given rule and same data set, which using a root context object to enable and disable matching,
    both attempt the same amount of matches and produce the same number of rule instances, and take roughly the same
    time. Except for the use case with subnetworks and accumulates. </p><p>PHREAK can however be considered more forgiving that RETE for poorly written rule bases and with a more graceful
    degradation of performance as the number of rules and complexity increases.</p><p>RETE will also churn away producing partial machines for rules that do not have data in all the joins; where as
    PHREAK will avoid this.</p><p> So it's not that PHREAK is faster than RETE, it just won't slow down as much as your system grows :) </p><p>AgendaGroups did not help in RETE performance, as all rules where evaluated at all times, regardless of the
    group. The same is true for salience. Which is why root context objects are often used, to limit matching attempts.
    PHREAK only evaluates rules for the active AgendaGroup, and within that group will attempt to avoid evaluation of
    rules (via salience) that do not result in rule instance firings. </p><p>With PHREAK AgendaGroups and salience now become useful performance tools. The root context objects are no
    longer needed and potentially counter productive to performance, as they force the flushing and recreation of
    matches for rules.</p><p> </p></div></div><script type="text/javascript" src="highlight.js/highlight.pack.js"> </script><script type="text/javascript">hljs.initHighlightingOnLoad();</script><ul class="docnav"><li class="previous"><a accesskey="p" href="pt03.html"><strong>Prev</strong>Part III. Drools Runtime and Language</a></li><li class="up"><a accesskey="u" href="#"><strong>Up</strong></a></li><li class="home"><a accesskey="h" href="index.html"><strong>Home</strong></a></li><li class="next"><a accesskey="n" href="ch06.html"><strong>Next</strong>Chapter 6. User Guide</a></li></ul></body></html>